{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5bac82-6256-4f59-af37-5a2ed3fc0640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported RAG system\n",
      "üöÄ RAG Grid Test - Enhanced Stability Version\n",
      "üîß This will test 12 LLM configurations with 5 queries each (60 total tests)\n",
      "‚è±Ô∏è  Estimated time: 15-20 minutes\n",
      "üõ°Ô∏è  Enhanced error handling for broken pipe and connection issues\n",
      "‚ö†Ô∏è  Press Ctrl+C to interrupt gracefully and save partial results\n",
      "\n",
      "üöÄ Starting Enhanced RAG Grid Test Suite\n",
      "================================================================================\n",
      "üìã Testing 12 configurations with 5 queries each\n",
      "üìä Total tests: 60\n",
      "‚ö†Ô∏è  Press Ctrl+C to interrupt gracefully\n",
      "================================================================================\n",
      "\n",
      "üîß Configuration 1/12: Temp 0.1, Top-P 0.8\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.1, P=0.8, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [1.7% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 258 words, 4 sources, 212.09s\n",
      "  Query 2/5 [3.3% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 242 words, 4 sources, 212.72s\n",
      "  Query 3/5 [5.0% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 264 words, 3 sources, 196.04s\n",
      "  Query 4/5 [6.7% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 253 words, 4 sources, 205.98s\n",
      "  Query 5/5 [8.3% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 287 words, 3 sources, 205.40s\n",
      "   üìà Config Summary: Avg time 206.45s, Avg length 1889 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 2/12: Temp 0.1, Top-P 0.9\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.1, P=0.9, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [10.0% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 260 words, 4 sources, 211.57s\n",
      "  Query 2/5 [11.7% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 233 words, 4 sources, 212.33s\n",
      "  Query 3/5 [13.3% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 260 words, 3 sources, 195.49s\n",
      "  Query 4/5 [15.0% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 265 words, 4 sources, 205.55s\n",
      "  Query 5/5 [16.7% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 281 words, 3 sources, 205.06s\n",
      "   üìà Config Summary: Avg time 206.00s, Avg length 1873 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 3/12: Temp 0.1, Top-P 0.95\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.1, P=0.95, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [18.3% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 248 words, 4 sources, 210.43s\n",
      "  Query 2/5 [20.0% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 247 words, 4 sources, 209.91s\n",
      "  Query 3/5 [21.7% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 264 words, 3 sources, 193.29s\n",
      "  Query 4/5 [23.3% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 254 words, 4 sources, 207.15s\n",
      "  Query 5/5 [25.0% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 284 words, 3 sources, 205.46s\n",
      "   üìà Config Summary: Avg time 205.25s, Avg length 1895 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 4/12: Temp 0.2, Top-P 0.8\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.2, P=0.8, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [26.7% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 247 words, 4 sources, 212.04s\n",
      "  Query 2/5 [28.3% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 254 words, 4 sources, 212.56s\n",
      "  Query 3/5 [30.0% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 259 words, 3 sources, 195.70s\n",
      "  Query 4/5 [31.7% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 263 words, 4 sources, 205.67s\n",
      "  Query 5/5 [33.3% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 286 words, 3 sources, 206.48s\n",
      "   üìà Config Summary: Avg time 206.49s, Avg length 1918 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 5/12: Temp 0.2, Top-P 0.9\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.2, P=0.9, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [35.0% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 268 words, 4 sources, 209.19s\n",
      "  Query 2/5 [36.7% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 246 words, 4 sources, 209.96s\n",
      "  Query 3/5 [38.3% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 274 words, 3 sources, 193.28s\n",
      "  Query 4/5 [40.0% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 263 words, 4 sources, 203.20s\n",
      "  Query 5/5 [41.7% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 286 words, 3 sources, 202.84s\n",
      "   üìà Config Summary: Avg time 203.69s, Avg length 1941 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 6/12: Temp 0.2, Top-P 0.95\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.2, P=0.95, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [43.3% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 247 words, 4 sources, 209.30s\n",
      "  Query 2/5 [45.0% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 276 words, 4 sources, 210.09s\n",
      "  Query 3/5 [46.7% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 264 words, 3 sources, 193.28s\n",
      "  Query 4/5 [48.3% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 259 words, 4 sources, 203.21s\n",
      "  Query 5/5 [50.0% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 283 words, 3 sources, 202.76s\n",
      "   üìà Config Summary: Avg time 203.73s, Avg length 1938 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 7/12: Temp 0.4, Top-P 0.8\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.4, P=0.8, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [51.7% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 272 words, 4 sources, 209.16s\n",
      "  Query 2/5 [53.3% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 233 words, 4 sources, 209.86s\n",
      "  Query 3/5 [55.0% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 273 words, 3 sources, 193.49s\n",
      "  Query 4/5 [56.7% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 259 words, 4 sources, 203.26s\n",
      "  Query 5/5 [58.3% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 290 words, 3 sources, 202.86s\n",
      "   üìà Config Summary: Avg time 203.73s, Avg length 1916 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 8/12: Temp 0.4, Top-P 0.9\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.4, P=0.9, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [60.0% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 256 words, 4 sources, 209.22s\n",
      "  Query 2/5 [61.7% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 239 words, 4 sources, 209.93s\n",
      "  Query 3/5 [63.3% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 277 words, 3 sources, 193.32s\n",
      "  Query 4/5 [65.0% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 266 words, 4 sources, 203.20s\n",
      "  Query 5/5 [66.7% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 294 words, 3 sources, 202.81s\n",
      "   üìà Config Summary: Avg time 203.70s, Avg length 1911 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 9/12: Temp 0.4, Top-P 0.95\n",
      "   Focus: temperature_top_p_balance\n",
      "   Settings: T=0.4, P=0.95, K=15, Tokens=400\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [68.3% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 258 words, 4 sources, 209.22s\n",
      "  Query 2/5 [70.0% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 258 words, 4 sources, 209.88s\n",
      "  Query 3/5 [71.7% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 266 words, 3 sources, 193.16s\n",
      "  Query 4/5 [73.3% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 281 words, 4 sources, 203.18s\n",
      "  Query 5/5 [75.0% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 279 words, 3 sources, 202.78s\n",
      "   üìà Config Summary: Avg time 203.65s, Avg length 1926 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 10/12: High Creativity\n",
      "   Focus: creative_responses\n",
      "   Settings: T=0.6, P=0.95, K=25, Tokens=500\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [76.7% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 294 words, 4 sources, 238.10s\n",
      "  Query 2/5 [78.3% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 310 words, 4 sources, 238.78s\n",
      "  Query 3/5 [80.0% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 326 words, 3 sources, 222.20s\n",
      "  Query 4/5 [81.7% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 352 words, 4 sources, 232.18s\n",
      "  Query 5/5 [83.3% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 364 words, 3 sources, 231.74s\n",
      "   üìà Config Summary: Avg time 232.60s, Avg length 2431 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 11/12: Maximum Precision\n",
      "   Focus: precise_factual\n",
      "   Settings: T=0.05, P=0.7, K=5, Tokens=300\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [85.0% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 203 words, 4 sources, 180.41s\n",
      "  Query 2/5 [86.7% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 202 words, 4 sources, 181.10s\n",
      "  Query 3/5 [88.3% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 209 words, 3 sources, 169.22s\n",
      "  Query 4/5 [90.0% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 200 words, 4 sources, 182.45s\n",
      "  Query 5/5 [91.7% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 215 words, 3 sources, 180.08s\n",
      "   üìà Config Summary: Avg time 178.65s, Avg length 1510 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "üîß Configuration 12/12: Extended Context\n",
      "   Focus: comprehensive_answers\n",
      "   Settings: T=0.25, P=0.85, K=15, Tokens=600\n",
      "üîß Setting up RAG (attempt 1/5)...\n",
      "   üì° Creating RAG instance...\n",
      "   üöÄ Initializing RAG components...\n",
      "üîß Loading attempt 1 for all-MiniLM-L6-v2 on cpu\n",
      "  Loading model on CPU first...\n",
      "  Fixing meta tensors...\n",
      "  Testing model with sample input...\n",
      "  Verifying no meta tensors remain...\n",
      "  ‚úÖ Model loaded successfully on cpu\n",
      "üîß Loading CrossEncoder attempt 1 on cpu\n",
      "  Loading CrossEncoder on CPU first...\n",
      "  Fixing CrossEncoder meta tensors...\n",
      "  Testing CrossEncoder...\n",
      "  ‚úÖ CrossEncoder loaded successfully on cpu\n",
      "   ‚úÖ RAG setup successful\n",
      "   üß™ Testing connection...\n",
      "   ‚úÖ Connection test passed\n",
      "  Query 1/5 [93.3% total]\n",
      "  üîç Testing query: What is cap rate and how do you calculate it?...\n",
      "    ‚úÖ Success: 352 words, 4 sources, 279.05s\n",
      "  Query 2/5 [95.0% total]\n",
      "  üîç Testing query: How do I analyze cash flow for a rental property i......\n",
      "    ‚úÖ Success: 329 words, 4 sources, 289.45s\n",
      "  Query 3/5 [96.7% total]\n",
      "  üîç Testing query: What are the key differences between commercial an......\n",
      "    ‚úÖ Success: 420 words, 3 sources, 279.98s\n",
      "  Query 4/5 [98.3% total]\n",
      "  üîç Testing query: Explain the risks involved in real estate investme......\n",
      "    ‚úÖ Success: 405 words, 4 sources, 295.66s\n",
      "  Query 5/5 [100.0% total]\n",
      "  üîç Testing query: What factors should I consider when choosing an in......\n",
      "    ‚úÖ Success: 422 words, 3 sources, 300.29s\n",
      "   üìà Config Summary: Avg time 288.89s, Avg length 2813 chars, 0 errors\n",
      "   üßπ Cleaning up configuration...\n",
      "\n",
      "‚úÖ Test suite completed in 15702.83 seconds\n",
      "üìä Total results: 60\n",
      "\n",
      "================================================================================\n",
      "üìä COMPREHENSIVE TEST ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üéØ Overall Performance:\n",
      "   Total tests: 60\n",
      "   Successful: 60\n",
      "   Error rate: 0.0%\n",
      "\n",
      "‚ö° Performance Metrics (Successful Tests):\n",
      "   Avg Response Time: 211.90s\n",
      "   Avg Answer Length: 1997 characters\n",
      "   Avg Word Count: 275 words\n",
      "   Avg Sources Used: 3.6\n",
      "   Avg Similarity Score: 0.000\n",
      "\n",
      "üèÜ Quality Analysis:\n",
      "   Basic Quality Score: 0.800\n",
      "   Advanced Quality Score: 0.720\n",
      "   Overall Quality Score: 0.768\n",
      "\n",
      "ü•á Configuration Rankings:\n",
      "\n",
      "   Top 5 Configurations:\n",
      "   1. Temp 0.1, Top-P 0.9\n",
      "      Composite Score: 0.680\n",
      "      Quality: 0.800\n",
      "      Avg Time: 206.00s\n",
      "      Error Rate: 0.0%\n",
      "   2. Temp 0.2, Top-P 0.8\n",
      "      Composite Score: 0.670\n",
      "      Quality: 0.784\n",
      "      Avg Time: 206.49s\n",
      "      Error Rate: 0.0%\n",
      "   3. Temp 0.2, Top-P 0.9\n",
      "      Composite Score: 0.670\n",
      "      Quality: 0.784\n",
      "      Avg Time: 203.69s\n",
      "      Error Rate: 0.0%\n",
      "   4. Temp 0.4, Top-P 0.9\n",
      "      Composite Score: 0.670\n",
      "      Quality: 0.784\n",
      "      Avg Time: 203.70s\n",
      "      Error Rate: 0.0%\n",
      "   5. Temp 0.4, Top-P 0.95\n",
      "      Composite Score: 0.670\n",
      "      Quality: 0.784\n",
      "      Avg Time: 203.65s\n",
      "      Error Rate: 0.0%\n",
      "\n",
      "üìù Query Type Performance:\n",
      "   Question: Quality 0.782, Time 211.74s, Length 1969 chars\n",
      "   Explanation: Quality 0.713, Time 212.56s, Length 2109 chars\n",
      "‚úÖ Results saved to rag_test_results_20250727_213108.json\n",
      "‚úÖ CSV results saved to rag_test_results_20250727_213108.csv\n",
      "‚úÖ Config summary saved to rag_config_summary_20250727_213108.csv\n",
      "\n",
      "üíæ Results saved:\n",
      "   üìä CSV: 'rag_test_results_20250727_213108.csv' (for Excel/analysis)\n",
      "   üìã JSON: 'rag_test_results_20250727_213108.json' (detailed data)\n",
      "================================================================================\n",
      "\n",
      "üéâ Grid test completed successfully!\n",
      "üìä Check the generated JSON and CSV files for detailed results\n",
      "üßπ Final cleanup...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import statistics\n",
    "import traceback\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import signal\n",
    "\n",
    "# Import your RAG system\n",
    "try:\n",
    "    from rag_script_24 import ConfigurableRAG, DEFAULT_CONFIG, create_rag_instance\n",
    "    print(\"‚úÖ Successfully imported RAG system\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import RAG system: {e}\")\n",
    "    print(\"Make sure your RAG file is named correctly or update the import\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def safe_mean(values: List[float], default: float = 0.0) -> float:\n",
    "    \"\"\"Safely calculate mean, returning default if list is empty.\"\"\"\n",
    "    return statistics.mean(values) if values else default\n",
    "\n",
    "def safe_max(values: List[float], default: float = 0.0) -> float:\n",
    "    \"\"\"Safely calculate max, returning default if list is empty.\"\"\"\n",
    "    return max(values) if values else default\n",
    "\n",
    "def safe_min(values: List[float], default: float = 0.0) -> float:\n",
    "    \"\"\"Safely calculate min, returning default if list is empty.\"\"\"\n",
    "    return min(values) if values else default\n",
    "\n",
    "def safe_variance(values: List[float], default: float = 0.0) -> float:\n",
    "    \"\"\"Safely calculate variance, returning default if list is empty or has one element.\"\"\"\n",
    "    return statistics.variance(values) if len(values) > 1 else default\n",
    "\n",
    "@dataclass\n",
    "class TestResult:\n",
    "    \"\"\"Comprehensive test result container.\"\"\"\n",
    "    config_id: str\n",
    "    config_name: str\n",
    "    query: str\n",
    "    query_type: str\n",
    "    answer: str\n",
    "    response_time: float\n",
    "    answer_length: int\n",
    "    word_count: int\n",
    "    sentence_count: int\n",
    "    sources_count: int\n",
    "    chunks_used: int\n",
    "    similarity_scores: List[float]\n",
    "    quality_scores: List[float]\n",
    "    cross_encoder_scores: List[float]\n",
    "    cached: bool\n",
    "    error: str = None\n",
    "    \n",
    "    # Computed quality metrics\n",
    "    avg_similarity: float = 0.0\n",
    "    max_similarity: float = 0.0\n",
    "    min_similarity: float = 0.0\n",
    "    avg_quality: float = 0.0\n",
    "    avg_cross_encoder: float = 0.0\n",
    "    similarity_variance: float = 0.0\n",
    "    information_density: float = 0.0\n",
    "    technical_terms_count: int = 0\n",
    "    numerical_data_count: int = 0\n",
    "    concrete_examples: int = 0\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Calculate derived metrics with safe operations.\"\"\"\n",
    "        # Similarity metrics - using safe functions\n",
    "        self.avg_similarity = safe_mean(self.similarity_scores)\n",
    "        self.max_similarity = safe_max(self.similarity_scores)\n",
    "        self.min_similarity = safe_min(self.similarity_scores)\n",
    "        self.similarity_variance = safe_variance(self.similarity_scores)\n",
    "        \n",
    "        # Quality metrics\n",
    "        self.avg_quality = safe_mean(self.quality_scores)\n",
    "        \n",
    "        # Cross-encoder metrics\n",
    "        self.avg_cross_encoder = safe_mean(self.cross_encoder_scores)\n",
    "        \n",
    "        # Content analysis\n",
    "        self._analyze_content()\n",
    "    \n",
    "    def _analyze_content(self):\n",
    "        \"\"\"Analyze answer content for quality indicators.\"\"\"\n",
    "        if not self.answer:\n",
    "            return\n",
    "        \n",
    "        answer_lower = self.answer.lower()\n",
    "        \n",
    "        # Count technical terms\n",
    "        re_terms = [\n",
    "            'cap rate', 'noi', 'cash flow', 'roi', 'irr', 'debt service',\n",
    "            'capitalization', 'dcf', 'appreciation', 'vacancy', 'operating expenses',\n",
    "            'gross rent multiplier', 'debt-to-equity', 'leverage', 'amortization',\n",
    "            'depreciation', 'basis points', 'yield', 'market value', 'appraisal'\n",
    "        ]\n",
    "        self.technical_terms_count = sum(1 for term in re_terms if term in answer_lower)\n",
    "        \n",
    "        # Count numerical data (percentages, dollar amounts, ratios)\n",
    "        import re\n",
    "        numbers = re.findall(r'\\b\\d+(?:,\\d{3})*(?:\\.\\d+)?[%$]?|\\$[\\d,]+(?:\\.\\d{2})?|\\d+:\\d+|\\d+\\.?\\d*%', self.answer)\n",
    "        self.numerical_data_count = len(numbers)\n",
    "        \n",
    "        # Count concrete examples (sentences with \"for example\", \"such as\", specific scenarios)\n",
    "        example_indicators = ['for example', 'such as', 'for instance', 'consider', 'suppose']\n",
    "        self.concrete_examples = sum(1 for indicator in example_indicators if indicator in answer_lower)\n",
    "        \n",
    "        # Information density (technical terms + numbers per 100 words)\n",
    "        if self.word_count > 0:\n",
    "            self.information_density = ((self.technical_terms_count + self.numerical_data_count) / self.word_count) * 100\n",
    "\n",
    "class RAGGridTester:\n",
    "    \"\"\"Comprehensive RAG testing with multiple configurations and quality metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_config = DEFAULT_CONFIG.copy()\n",
    "        self.rag_instance = None\n",
    "        self.test_results = []\n",
    "        self.config_performance = defaultdict(list)\n",
    "        self.interrupted = False\n",
    "        \n",
    "        # Setup signal handler for graceful interruption\n",
    "        signal.signal(signal.SIGINT, self._signal_handler)\n",
    "        \n",
    "        # Test queries covering different types and complexities\n",
    "        self.test_queries = [\n",
    "            \"What is cap rate and how do you calculate it?\",\n",
    "            \"How do I analyze cash flow for a rental property investment?\",\n",
    "            \"What are the key differences between commercial and residential real estate investing?\",\n",
    "            \"Explain the risks involved in real estate investment and how to mitigate them\",\n",
    "            \"What factors should I consider when choosing an investment property location?\"\n",
    "        ]\n",
    "        \n",
    "        # Quality thresholds for evaluation\n",
    "        self.quality_thresholds = {\n",
    "            'min_answer_length': 200,\n",
    "            'min_word_count': 30,\n",
    "            'min_similarity': 0.15,\n",
    "            'min_sources': 1,\n",
    "            'max_response_time': 45.0,  # Increased timeout\n",
    "            'min_technical_terms': 2,\n",
    "            'min_information_density': 1.0\n",
    "        }\n",
    "    \n",
    "    def _signal_handler(self, signum, frame):\n",
    "        \"\"\"Handle interrupt signals gracefully.\"\"\"\n",
    "        print(\"\\n‚ö†Ô∏è  Interrupt received. Finishing current test and saving results...\")\n",
    "        self.interrupted = True\n",
    "    \n",
    "    def cleanup_rag(self):\n",
    "        \"\"\"Properly cleanup RAG instance to prevent resource leaks.\"\"\"\n",
    "        if self.rag_instance:\n",
    "            try:\n",
    "                # Try to access model attribute safely\n",
    "                if hasattr(self.rag_instance, 'model') and self.rag_instance.model:\n",
    "                    del self.rag_instance.model\n",
    "                \n",
    "                # Clear any other resources\n",
    "                if hasattr(self.rag_instance, 'vectorstore'):\n",
    "                    del self.rag_instance.vectorstore\n",
    "                \n",
    "                if hasattr(self.rag_instance, 'embeddings'):\n",
    "                    del self.rag_instance.embeddings\n",
    "                \n",
    "                del self.rag_instance\n",
    "                self.rag_instance = None\n",
    "                \n",
    "                # Force garbage collection\n",
    "                gc.collect()\n",
    "                \n",
    "                # Brief pause to allow cleanup\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Warning during cleanup: {e}\")\n",
    "                # Force cleanup anyway\n",
    "                self.rag_instance = None\n",
    "                gc.collect()\n",
    "    \n",
    "    def generate_test_configurations(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate 12 smart LLM configurations for comprehensive testing.\"\"\"\n",
    "        configs = []\n",
    "        \n",
    "        # Base configuration variations\n",
    "        base_temps = [0.1, 0.2, 0.4]  # Conservative, balanced, creative\n",
    "        base_top_ps = [0.8, 0.9, 0.95]  # Focused, balanced, diverse\n",
    "        \n",
    "        # Configuration 1-9: Temperature and top_p matrix\n",
    "        for i, temp in enumerate(base_temps):\n",
    "            for j, top_p in enumerate(base_top_ps):\n",
    "                config = self.base_config.copy()\n",
    "                config['llm_options'] = config['llm_options'].copy()\n",
    "                config['llm_options']['temperature'] = temp\n",
    "                config['llm_options']['top_p'] = top_p\n",
    "                config['llm_options']['num_predict'] = 400\n",
    "                config['llm_options']['top_k'] = 15\n",
    "                # Add connection stability options\n",
    "                config['llm_options']['num_ctx'] = 2048\n",
    "                config['llm_options']['repeat_penalty'] = 1.1\n",
    "                \n",
    "                configs.append({\n",
    "                    'id': f'temp_{temp}_top_p_{top_p}',\n",
    "                    'name': f'Temp {temp}, Top-P {top_p}',\n",
    "                    'config': config,\n",
    "                    'focus': 'temperature_top_p_balance'\n",
    "                })\n",
    "        \n",
    "        # Configuration 10: High creativity\n",
    "        config = self.base_config.copy()\n",
    "        config['llm_options'] = config['llm_options'].copy()\n",
    "        config['llm_options']['temperature'] = 0.6\n",
    "        config['llm_options']['top_p'] = 0.95\n",
    "        config['llm_options']['top_k'] = 25\n",
    "        config['llm_options']['num_predict'] = 500\n",
    "        config['llm_options']['num_ctx'] = 2048\n",
    "        configs.append({\n",
    "            'id': 'high_creativity',\n",
    "            'name': 'High Creativity',\n",
    "            'config': config,\n",
    "            'focus': 'creative_responses'\n",
    "        })\n",
    "        \n",
    "        # Configuration 11: Maximum precision\n",
    "        config = self.base_config.copy()\n",
    "        config['llm_options'] = config['llm_options'].copy()\n",
    "        config['llm_options']['temperature'] = 0.05\n",
    "        config['llm_options']['top_p'] = 0.7\n",
    "        config['llm_options']['top_k'] = 5\n",
    "        config['llm_options']['num_predict'] = 300\n",
    "        config['llm_options']['repeat_penalty'] = 1.1\n",
    "        config['llm_options']['num_ctx'] = 2048\n",
    "        configs.append({\n",
    "            'id': 'max_precision',\n",
    "            'name': 'Maximum Precision',\n",
    "            'config': config,\n",
    "            'focus': 'precise_factual'\n",
    "        })\n",
    "        \n",
    "        # Configuration 12: Extended context\n",
    "        config = self.base_config.copy()\n",
    "        config['llm_options'] = config['llm_options'].copy()\n",
    "        config['llm_options']['temperature'] = 0.25\n",
    "        config['llm_options']['top_p'] = 0.85\n",
    "        config['llm_options']['num_predict'] = 600\n",
    "        config['llm_options']['num_ctx'] = 4096\n",
    "        config['max_context_length'] = 3000\n",
    "        config['max_context_chunks'] = 6\n",
    "        configs.append({\n",
    "            'id': 'extended_context',\n",
    "            'name': 'Extended Context',\n",
    "            'config': config,\n",
    "            'focus': 'comprehensive_answers'\n",
    "        })\n",
    "        \n",
    "        return configs\n",
    "    \n",
    "    def setup_rag(self, config: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Setup RAG instance with improved retry mechanism and error handling.\"\"\"\n",
    "        max_retries = 5  # Increased retries\n",
    "        retry_delays = [2, 4, 6, 8, 10]  # Progressive delays\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(f\"üîß Setting up RAG (attempt {attempt + 1}/{max_retries})...\")\n",
    "                \n",
    "                # Cleanup any existing instance first\n",
    "                self.cleanup_rag()\n",
    "                \n",
    "                # Additional cleanup time for first attempt failures\n",
    "                if attempt > 0:\n",
    "                    print(f\"   ‚è≥ Waiting {retry_delays[attempt-1]}s before retry...\")\n",
    "                    time.sleep(retry_delays[attempt-1])\n",
    "                \n",
    "                # Create new instance with timeout handling\n",
    "                print(\"   üì° Creating RAG instance...\")\n",
    "                self.rag_instance = create_rag_instance(config)\n",
    "                \n",
    "                if not self.rag_instance:\n",
    "                    raise Exception(\"Failed to create RAG instance\")\n",
    "                \n",
    "                # Set verbose to false to reduce noise\n",
    "                if hasattr(self.rag_instance, 'set_verbose'):\n",
    "                    self.rag_instance.set_verbose(False)\n",
    "                \n",
    "                print(\"   üöÄ Initializing RAG components...\")\n",
    "                setup_success = self.rag_instance.setup()\n",
    "                \n",
    "                if setup_success:\n",
    "                    print(\"   ‚úÖ RAG setup successful\")\n",
    "                    \n",
    "                    # Test the connection with a simple query\n",
    "                    print(\"   üß™ Testing connection...\")\n",
    "                    try:\n",
    "                        test_result = self.rag_instance.ask(\"test\", use_cache=False)\n",
    "                        if test_result and 'answer' in test_result:\n",
    "                            print(\"   ‚úÖ Connection test passed\")\n",
    "                            return True\n",
    "                        else:\n",
    "                            raise Exception(\"Connection test failed - no valid response\")\n",
    "                    except Exception as test_e:\n",
    "                        print(f\"   ‚ùå Connection test failed: {test_e}\")\n",
    "                        raise test_e\n",
    "                else:\n",
    "                    raise Exception(\"RAG setup returned False\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                print(f\"   ‚ùå Setup attempt {attempt + 1} failed: {error_msg}\")\n",
    "                \n",
    "                # Cleanup on failure\n",
    "                self.cleanup_rag()\n",
    "                \n",
    "                # Check for specific error types\n",
    "                if \"broken pipe\" in error_msg.lower() or \"connection\" in error_msg.lower():\n",
    "                    print(f\"   üîå Detected connection issue, extending retry delay...\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        extra_delay = 5 + (attempt * 2)\n",
    "                        time.sleep(extra_delay)\n",
    "                \n",
    "                if attempt == max_retries - 1:\n",
    "                    print(\"   üíÄ All setup attempts failed\")\n",
    "                    return False\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def run_query_test(self, query: str, config_id: str, config_name: str) -> TestResult:\n",
    "        \"\"\"Run a single query test with improved error handling and retry logic.\"\"\"\n",
    "        max_retries = 3\n",
    "        retry_delays = [2, 5, 10]\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(f\"  üîç Testing query: {query[:50]}...\" + (\"...\" if len(query) > 50 else \"\"))\n",
    "                \n",
    "                # Check if RAG instance is still valid\n",
    "                if not self.rag_instance:\n",
    "                    raise Exception(\"RAG instance is None\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Add timeout wrapper for the query\n",
    "                try:\n",
    "                    result = self.rag_instance.ask(query, use_cache=False)\n",
    "                except Exception as query_error:\n",
    "                    # Check for broken pipe or connection errors\n",
    "                    if \"broken pipe\" in str(query_error).lower() or \"connection\" in str(query_error).lower():\n",
    "                        print(f\"    üîå Connection error detected: {query_error}\")\n",
    "                        raise query_error\n",
    "                    else:\n",
    "                        # Re-raise other errors\n",
    "                        raise query_error\n",
    "                \n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Validate result\n",
    "                if not result or not isinstance(result, dict):\n",
    "                    raise Exception(\"Invalid result format\")\n",
    "                \n",
    "                # Extract comprehensive metrics with safe defaults\n",
    "                answer = result.get('answer', '') or ''\n",
    "                sources = result.get('sources', []) or []\n",
    "                query_info = result.get('query_info', {}) or {}\n",
    "                \n",
    "                # Basic metrics with safe calculations\n",
    "                word_count = len(answer.split()) if answer else 0\n",
    "                sentence_count = len([s for s in answer.split('.') if s.strip()]) if answer else 0\n",
    "                \n",
    "                # Source quality metrics with safe extraction\n",
    "                similarity_scores = []\n",
    "                quality_scores = []\n",
    "                cross_encoder_scores = []\n",
    "                \n",
    "                for s in sources:\n",
    "                    if isinstance(s, dict):\n",
    "                        if 'similarity' in s and s['similarity'] is not None:\n",
    "                            try:\n",
    "                                similarity_scores.append(float(s['similarity']))\n",
    "                            except (ValueError, TypeError):\n",
    "                                pass\n",
    "                        if 'quality_score' in s and s['quality_score'] is not None:\n",
    "                            try:\n",
    "                                quality_scores.append(float(s['quality_score']))\n",
    "                            except (ValueError, TypeError):\n",
    "                                pass\n",
    "                        if 'cross_encoder_score' in s and s['cross_encoder_score'] is not None:\n",
    "                            try:\n",
    "                                cross_encoder_scores.append(float(s['cross_encoder_score']))\n",
    "                            except (ValueError, TypeError):\n",
    "                                pass\n",
    "                \n",
    "                test_result = TestResult(\n",
    "                    config_id=config_id,\n",
    "                    config_name=config_name,\n",
    "                    query=query,\n",
    "                    query_type=query_info.get('query_type', 'unknown'),\n",
    "                    answer=answer,\n",
    "                    response_time=end_time - start_time,\n",
    "                    answer_length=len(answer),\n",
    "                    word_count=word_count,\n",
    "                    sentence_count=sentence_count,\n",
    "                    sources_count=len(sources),\n",
    "                    chunks_used=result.get('chunks_used', 0) or 0,\n",
    "                    similarity_scores=similarity_scores,\n",
    "                    quality_scores=quality_scores,\n",
    "                    cross_encoder_scores=cross_encoder_scores,\n",
    "                    cached=result.get('cached', False) or False,\n",
    "                    error=result.get('error')\n",
    "                )\n",
    "                \n",
    "                print(f\"    ‚úÖ Success: {word_count} words, {len(sources)} sources, {test_result.response_time:.2f}s\")\n",
    "                return test_result\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Query test error (attempt {attempt + 1}): {str(e)[:200]}\"\n",
    "                print(f\"    ‚ùå {error_msg}\")\n",
    "                \n",
    "                # Handle broken pipe specifically\n",
    "                if \"broken pipe\" in str(e).lower() or \"connection\" in str(e).lower():\n",
    "                    print(f\"    üîå Connection lost, attempting recovery...\")\n",
    "                    \n",
    "                    # Try to recover by recreating the RAG instance\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"    üîÑ Recreating RAG instance...\")\n",
    "                        try:\n",
    "                            # Get current config from the existing instance\n",
    "                            current_config = getattr(self.rag_instance, 'config', self.base_config)\n",
    "                            \n",
    "                            # Cleanup and recreate\n",
    "                            self.cleanup_rag()\n",
    "                            time.sleep(retry_delays[attempt])\n",
    "                            \n",
    "                            # Try to recreate with same config\n",
    "                            if self.setup_rag(current_config):\n",
    "                                print(f\"    ‚úÖ RAG instance recovered\")\n",
    "                            else:\n",
    "                                print(f\"    ‚ùå Failed to recover RAG instance\")\n",
    "                                break\n",
    "                        except Exception as recovery_error:\n",
    "                            print(f\"    ‚ùå Recovery failed: {recovery_error}\")\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    # For other errors, just wait and retry\n",
    "                    if attempt < max_retries - 1:\n",
    "                        time.sleep(retry_delays[attempt])\n",
    "                \n",
    "                if attempt == max_retries - 1:\n",
    "                    # Return error result\n",
    "                    return TestResult(\n",
    "                        config_id=config_id,\n",
    "                        config_name=config_name,\n",
    "                        query=query,\n",
    "                        query_type='unknown',\n",
    "                        answer='',\n",
    "                        response_time=0.0,\n",
    "                        answer_length=0,\n",
    "                        word_count=0,\n",
    "                        sentence_count=0,\n",
    "                        sources_count=0,\n",
    "                        chunks_used=0,\n",
    "                        similarity_scores=[],\n",
    "                        quality_scores=[],\n",
    "                        cross_encoder_scores=[],\n",
    "                        cached=False,\n",
    "                        error=error_msg\n",
    "                    )\n",
    "        \n",
    "        # Fallback error result\n",
    "        return TestResult(\n",
    "            config_id=config_id,\n",
    "            config_name=config_name,\n",
    "            query=query,\n",
    "            query_type='unknown',\n",
    "            answer='',\n",
    "            response_time=0.0,\n",
    "            answer_length=0,\n",
    "            word_count=0,\n",
    "            sentence_count=0,\n",
    "            sources_count=0,\n",
    "            chunks_used=0,\n",
    "            similarity_scores=[],\n",
    "            quality_scores=[],\n",
    "            cross_encoder_scores=[],\n",
    "            cached=False,\n",
    "            error=\"Maximum retries exceeded\"\n",
    "        )\n",
    "    \n",
    "    def evaluate_result_quality(self, result: TestResult) -> Dict[str, Any]:\n",
    "        \"\"\"Evaluate result quality against multiple metrics.\"\"\"\n",
    "        quality_metrics = {}\n",
    "        \n",
    "        # Basic quality checks\n",
    "        quality_metrics['meets_min_length'] = result.answer_length >= self.quality_thresholds['min_answer_length']\n",
    "        quality_metrics['meets_min_words'] = result.word_count >= self.quality_thresholds['min_word_count']\n",
    "        quality_metrics['has_sources'] = result.sources_count >= self.quality_thresholds['min_sources']\n",
    "        quality_metrics['reasonable_response_time'] = result.response_time <= self.quality_thresholds['max_response_time']\n",
    "        quality_metrics['no_error'] = result.error is None\n",
    "        \n",
    "        # Advanced quality metrics\n",
    "        quality_metrics['good_similarity'] = result.avg_similarity >= self.quality_thresholds['min_similarity']\n",
    "        quality_metrics['technical_content'] = result.technical_terms_count >= self.quality_thresholds['min_technical_terms']\n",
    "        quality_metrics['information_dense'] = result.information_density >= self.quality_thresholds['min_information_density']\n",
    "        quality_metrics['has_examples'] = result.concrete_examples > 0\n",
    "        quality_metrics['has_numbers'] = result.numerical_data_count > 0\n",
    "        \n",
    "        # Composite scores\n",
    "        basic_quality_score = sum([\n",
    "            quality_metrics['meets_min_length'],\n",
    "            quality_metrics['meets_min_words'],\n",
    "            quality_metrics['has_sources'],\n",
    "            quality_metrics['reasonable_response_time'],\n",
    "            quality_metrics['no_error']\n",
    "        ]) / 5.0\n",
    "        \n",
    "        advanced_quality_score = sum([\n",
    "            quality_metrics['good_similarity'],\n",
    "            quality_metrics['technical_content'],\n",
    "            quality_metrics['information_dense'],\n",
    "            quality_metrics['has_examples'],\n",
    "            quality_metrics['has_numbers']\n",
    "        ]) / 5.0\n",
    "        \n",
    "        quality_metrics['basic_quality_score'] = basic_quality_score\n",
    "        quality_metrics['advanced_quality_score'] = advanced_quality_score\n",
    "        quality_metrics['overall_quality_score'] = (basic_quality_score * 0.6 + advanced_quality_score * 0.4)\n",
    "        \n",
    "        return quality_metrics\n",
    "    \n",
    "    def run_full_test_suite(self):\n",
    "        \"\"\"Run the complete test suite across all configurations with improved stability.\"\"\"\n",
    "        print(\"üöÄ Starting Enhanced RAG Grid Test Suite\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        configs = self.generate_test_configurations()\n",
    "        \n",
    "        print(f\"üìã Testing {len(configs)} configurations with {len(self.test_queries)} queries each\")\n",
    "        print(f\"üìä Total tests: {len(configs) * len(self.test_queries)}\")\n",
    "        print(\"‚ö†Ô∏è  Press Ctrl+C to interrupt gracefully\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        config_counter = 0\n",
    "        total_tests = len(configs) * len(self.test_queries)\n",
    "        completed_tests = 0\n",
    "        consecutive_failures = 0  # Track consecutive failures\n",
    "        \n",
    "        for config_info in configs:\n",
    "            if self.interrupted:\n",
    "                print(\"\\n‚ö†Ô∏è  Test suite interrupted by user\")\n",
    "                break\n",
    "            \n",
    "            config_counter += 1\n",
    "            config = config_info['config']\n",
    "            config_id = config_info['id']\n",
    "            config_name = config_info['name']\n",
    "            \n",
    "            print(f\"\\nüîß Configuration {config_counter}/{len(configs)}: {config_name}\")\n",
    "            print(f\"   Focus: {config_info['focus']}\")\n",
    "            print(f\"   Settings: T={config['llm_options']['temperature']}, \"\n",
    "                  f\"P={config['llm_options']['top_p']}, \"\n",
    "                  f\"K={config['llm_options']['top_k']}, \"\n",
    "                  f\"Tokens={config['llm_options']['num_predict']}\")\n",
    "            \n",
    "            # Setup RAG with this configuration\n",
    "            setup_success = self.setup_rag(config)\n",
    "            \n",
    "            if not setup_success:\n",
    "                print(f\"‚ùå Skipping configuration {config_name} due to setup failure\")\n",
    "                completed_tests += len(self.test_queries)\n",
    "                consecutive_failures += 1\n",
    "                \n",
    "                # If too many consecutive failures, pause longer\n",
    "                if consecutive_failures >= 3:\n",
    "                    print(\"‚ö†Ô∏è  Multiple consecutive failures detected. Taking extended break...\")\n",
    "                    time.sleep(30)\n",
    "                    consecutive_failures = 0\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            consecutive_failures = 0  # Reset on successful setup\n",
    "            \n",
    "            # Run all queries for this configuration\n",
    "            config_results = []\n",
    "            config_error_count = 0\n",
    "            \n",
    "            for query_idx, query in enumerate(self.test_queries):\n",
    "                if self.interrupted:\n",
    "                    break\n",
    "                \n",
    "                completed_tests += 1\n",
    "                progress = (completed_tests / total_tests) * 100\n",
    "                print(f\"  Query {query_idx + 1}/{len(self.test_queries)} [{progress:.1f}% total]\")\n",
    "                \n",
    "                result = self.run_query_test(query, config_id, config_name)\n",
    "                self.test_results.append(result)\n",
    "                config_results.append(result)\n",
    "                \n",
    "                if result.error:\n",
    "                    config_error_count += 1\n",
    "                    \n",
    "                    # If too many errors in this config, consider skipping remaining queries\n",
    "                    if config_error_count >= 3:\n",
    "                        print(f\"  ‚ö†Ô∏è  Too many errors in this configuration, may have connection issues\")\n",
    "                        # Brief pause to let things settle\n",
    "                        time.sleep(5)\n",
    "                \n",
    "                # Brief pause between queries to prevent overwhelming the system\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            if self.interrupted:\n",
    "                break\n",
    "            \n",
    "            # Quick config summary with safe calculations\n",
    "            response_times = [r.response_time for r in config_results if r.response_time > 0]\n",
    "            answer_lengths = [r.answer_length for r in config_results]\n",
    "            error_count = sum(1 for r in config_results if r.error)\n",
    "            \n",
    "            avg_time = safe_mean(response_times)\n",
    "            avg_length = safe_mean(answer_lengths)\n",
    "            \n",
    "            print(f\"   üìà Config Summary: Avg time {avg_time:.2f}s, \"\n",
    "                  f\"Avg length {avg_length:.0f} chars, {error_count} errors\")\n",
    "            \n",
    "            # Store config performance\n",
    "            self.config_performance[config_id] = config_results\n",
    "            \n",
    "            # Cleanup after each configuration to prevent resource buildup\n",
    "            print(f\"   üßπ Cleaning up configuration...\")\n",
    "            self.cleanup_rag()\n",
    "            time.sleep(2)  # Brief pause between configurations\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n‚úÖ Test suite completed in {total_time:.2f} seconds\")\n",
    "        print(f\"üìä Total results: {len(self.test_results)}\")\n",
    "        \n",
    "        # Final cleanup\n",
    "        self.cleanup_rag()\n",
    "        \n",
    "        # Generate comprehensive analysis\n",
    "        if self.test_results:\n",
    "            self.generate_comprehensive_analysis()\n",
    "        else:\n",
    "            print(\"‚ùå No test results to analyze\")\n",
    "    \n",
    "    def generate_comprehensive_analysis(self):\n",
    "        \"\"\"Generate detailed analysis of all test results.\"\"\"\n",
    "        if not self.test_results:\n",
    "            print(\"‚ùå No test results to analyze\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üìä COMPREHENSIVE TEST ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Overall statistics\n",
    "        total_tests = len(self.test_results)\n",
    "        successful_tests = len([r for r in self.test_results if not r.error])\n",
    "        error_rate = ((total_tests - successful_tests) / total_tests) * 100 if total_tests > 0 else 0\n",
    "        \n",
    "        print(f\"\\nüéØ Overall Performance:\")\n",
    "        print(f\"   Total tests: {total_tests}\")\n",
    "        print(f\"   Successful: {successful_tests}\")\n",
    "        print(f\"   Error rate: {error_rate:.1f}%\")\n",
    "        \n",
    "        # Performance metrics for successful tests\n",
    "        successful_results = [r for r in self.test_results if not r.error]\n",
    "        \n",
    "        if successful_results:\n",
    "            # Safe calculations for all metrics\n",
    "            response_times = [r.response_time for r in successful_results]\n",
    "            answer_lengths = [r.answer_length for r in successful_results]\n",
    "            word_counts = [r.word_count for r in successful_results]\n",
    "            sources_counts = [r.sources_count for r in successful_results]\n",
    "            similarity_scores = [r.avg_similarity for r in successful_results if r.avg_similarity > 0]\n",
    "            \n",
    "            avg_response_time = safe_mean(response_times)\n",
    "            avg_answer_length = safe_mean(answer_lengths)\n",
    "            avg_word_count = safe_mean(word_counts)\n",
    "            avg_sources = safe_mean(sources_counts)\n",
    "            avg_similarity = safe_mean(similarity_scores)\n",
    "            \n",
    "            print(f\"\\n‚ö° Performance Metrics (Successful Tests):\")\n",
    "            print(f\"   Avg Response Time: {avg_response_time:.2f}s\")\n",
    "            print(f\"   Avg Answer Length: {avg_answer_length:.0f} characters\")\n",
    "            print(f\"   Avg Word Count: {avg_word_count:.0f} words\")\n",
    "            print(f\"   Avg Sources Used: {avg_sources:.1f}\")\n",
    "            print(f\"   Avg Similarity Score: {avg_similarity:.3f}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö° No successful tests to analyze\")\n",
    "        \n",
    "        # Quality analysis\n",
    "        print(f\"\\nüèÜ Quality Analysis:\")\n",
    "        quality_results = []\n",
    "        \n",
    "        for result in successful_results:\n",
    "            quality_metrics = self.evaluate_result_quality(result)\n",
    "            quality_results.append(quality_metrics)\n",
    "        \n",
    "        if quality_results:\n",
    "            basic_scores = [q['basic_quality_score'] for q in quality_results]\n",
    "            advanced_scores = [q['advanced_quality_score'] for q in quality_results]\n",
    "            overall_scores = [q['overall_quality_score'] for q in quality_results]\n",
    "            \n",
    "            avg_basic_quality = safe_mean(basic_scores)\n",
    "            avg_advanced_quality = safe_mean(advanced_scores)\n",
    "            avg_overall_quality = safe_mean(overall_scores)\n",
    "            \n",
    "            print(f\"   Basic Quality Score: {avg_basic_quality:.3f}\")\n",
    "            print(f\"   Advanced Quality Score: {avg_advanced_quality:.3f}\")\n",
    "            print(f\"   Overall Quality Score: {avg_overall_quality:.3f}\")\n",
    "        else:\n",
    "            print(f\"   No quality results to analyze\")\n",
    "        \n",
    "        # Configuration ranking\n",
    "        print(f\"\\nü•á Configuration Rankings:\")\n",
    "        config_scores = {}\n",
    "        \n",
    "        for config_id, results in self.config_performance.items():\n",
    "            successful = [r for r in results if not r.error]\n",
    "            if successful:\n",
    "                # Calculate composite score with safe operations\n",
    "                response_times = [r.response_time for r in successful]\n",
    "                avg_time = safe_mean(response_times)\n",
    "                \n",
    "                quality_scores = [\n",
    "                    self.evaluate_result_quality(r)['overall_quality_score'] \n",
    "                    for r in successful\n",
    "                ]\n",
    "                avg_quality = safe_mean(quality_scores)\n",
    "                \n",
    "                error_rate = (len(results) - len(successful)) / len(results) if len(results) > 0 else 1.0\n",
    "                \n",
    "                # Composite score: quality (60%) + speed bonus (20%) + reliability (20%)\n",
    "                speed_bonus = max(0, (10 - avg_time) / 10) if avg_time > 0 else 0\n",
    "                reliability_bonus = 1 - error_rate\n",
    "                \n",
    "                composite_score = (avg_quality * 0.6 + \n",
    "                                 speed_bonus * 0.2 + \n",
    "                                 reliability_bonus * 0.2)\n",
    "                \n",
    "                config_scores[config_id] = {\n",
    "                    'composite_score': composite_score,\n",
    "                    'avg_quality': avg_quality,\n",
    "                    'avg_time': avg_time,\n",
    "                    'error_rate': error_rate,\n",
    "                    'results': results\n",
    "                }\n",
    "            else:\n",
    "                # All failed\n",
    "                config_scores[config_id] = {\n",
    "                    'composite_score': 0.0,\n",
    "                    'avg_quality': 0.0,\n",
    "                    'avg_time': 0.0,\n",
    "                    'error_rate': 1.0,\n",
    "                    'results': results\n",
    "                }\n",
    "        \n",
    "        # Sort configurations by composite score\n",
    "        ranked_configs = sorted(\n",
    "            config_scores.items(), \n",
    "            key=lambda x: x[1]['composite_score'], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        if ranked_configs:\n",
    "            print(\"\\n   Top 5 Configurations:\")\n",
    "            for i, (config_id, metrics) in enumerate(ranked_configs[:5]):\n",
    "                config_name = next((r.config_name for r in self.test_results if r.config_id == config_id), config_id)\n",
    "                print(f\"   {i+1}. {config_name}\")\n",
    "                print(f\"      Composite Score: {metrics['composite_score']:.3f}\")\n",
    "                print(f\"      Quality: {metrics['avg_quality']:.3f}\")\n",
    "                print(f\"      Avg Time: {metrics['avg_time']:.2f}s\")\n",
    "                print(f\"      Error Rate: {metrics['error_rate']*100:.1f}%\")\n",
    "        else:\n",
    "            print(\"   No configurations to rank\")\n",
    "        \n",
    "        # Query type analysis\n",
    "        print(f\"\\nüìù Query Type Performance:\")\n",
    "        query_type_performance = defaultdict(list)\n",
    "        \n",
    "        for result in successful_results:\n",
    "            if result.query_type:\n",
    "                quality_score = self.evaluate_result_quality(result)['overall_quality_score']\n",
    "                query_type_performance[result.query_type].append({\n",
    "                    'quality': quality_score,\n",
    "                    'time': result.response_time,\n",
    "                    'length': result.answer_length\n",
    "                })\n",
    "        \n",
    "        if query_type_performance:\n",
    "            for query_type, performances in query_type_performance.items():\n",
    "                quality_scores = [p['quality'] for p in performances]\n",
    "                times = [p['time'] for p in performances]\n",
    "                lengths = [p['length'] for p in performances]\n",
    "                \n",
    "                avg_quality = safe_mean(quality_scores)\n",
    "                avg_time = safe_mean(times)\n",
    "                avg_length = safe_mean(lengths)\n",
    "                \n",
    "                print(f\"   {query_type.title()}: Quality {avg_quality:.3f}, \"\n",
    "                      f\"Time {avg_time:.2f}s, Length {avg_length:.0f} chars\")\n",
    "        else:\n",
    "            print(\"   No query type data to analyze\")\n",
    "        \n",
    "        # Save detailed results\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        self.save_detailed_results(ranked_configs, timestamp)\n",
    "        self.save_csv_results(timestamp)\n",
    "        \n",
    "        print(f\"\\nüíæ Results saved:\")\n",
    "        print(f\"   üìä CSV: 'rag_test_results_{timestamp}.csv' (for Excel/analysis)\")\n",
    "        print(f\"   üìã JSON: 'rag_test_results_{timestamp}.json' (detailed data)\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def save_detailed_results(self, ranked_configs, timestamp):\n",
    "        \"\"\"Save comprehensive test results to JSON file.\"\"\"\n",
    "        filename = f'rag_test_results_{timestamp}.json'\n",
    "        \n",
    "        # Prepare data for JSON serialization\n",
    "        results_data = {\n",
    "            'test_metadata': {\n",
    "                'timestamp': timestamp,\n",
    "                'total_tests': len(self.test_results),\n",
    "                'total_configs': len(self.config_performance),\n",
    "                'queries_per_config': len(self.test_queries),\n",
    "                'test_queries': self.test_queries,\n",
    "                'quality_thresholds': self.quality_thresholds,\n",
    "                'interrupted': self.interrupted\n",
    "            },\n",
    "            'configuration_rankings': [\n",
    "                {\n",
    "                    'rank': i + 1,\n",
    "                    'config_id': config_id,\n",
    "                    'config_name': next((r.config_name for r in self.test_results if r.config_id == config_id), config_id),\n",
    "                    'composite_score': metrics['composite_score'],\n",
    "                    'avg_quality': metrics['avg_quality'],\n",
    "                    'avg_time': metrics['avg_time'],\n",
    "                    'error_rate': metrics['error_rate']\n",
    "                }\n",
    "                for i, (config_id, metrics) in enumerate(ranked_configs)\n",
    "            ],\n",
    "            'detailed_results': [\n",
    "                {\n",
    "                    **asdict(result),\n",
    "                    'quality_evaluation': self.evaluate_result_quality(result) if not result.error else None\n",
    "                }\n",
    "                for result in self.test_results\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"‚úÖ Results saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to save results: {e}\")\n",
    "    \n",
    "    def save_csv_results(self, timestamp):\n",
    "        \"\"\"Save test results to CSV format for easy analysis.\"\"\"\n",
    "        csv_filename = f'rag_test_results_{timestamp}.csv'\n",
    "        \n",
    "        try:\n",
    "            # Prepare data for CSV\n",
    "            csv_data = []\n",
    "            \n",
    "            for result in self.test_results:\n",
    "                # Get quality evaluation\n",
    "                quality_eval = self.evaluate_result_quality(result) if not result.error else {}\n",
    "                \n",
    "                # Create comprehensive row\n",
    "                row = {\n",
    "                    # Configuration info\n",
    "                    'config_id': result.config_id,\n",
    "                    'config_name': result.config_name,\n",
    "                    'query': result.query,\n",
    "                    'query_type': result.query_type,\n",
    "                    \n",
    "                    # Performance metrics\n",
    "                    'response_time_sec': result.response_time,\n",
    "                    'answer_length_chars': result.answer_length,\n",
    "                    'word_count': result.word_count,\n",
    "                    'sentence_count': result.sentence_count,\n",
    "                    'sources_count': result.sources_count,\n",
    "                    'chunks_used': result.chunks_used,\n",
    "                    'cached': result.cached,\n",
    "                    'error': result.error or '',\n",
    "                    \n",
    "                    # Similarity metrics\n",
    "                    'avg_similarity': result.avg_similarity,\n",
    "                    'max_similarity': result.max_similarity,\n",
    "                    'min_similarity': result.min_similarity,\n",
    "                    'similarity_variance': result.similarity_variance,\n",
    "                    \n",
    "                    # Quality metrics\n",
    "                    'avg_quality_score': result.avg_quality,\n",
    "                    'avg_cross_encoder_score': result.avg_cross_encoder,\n",
    "                    \n",
    "                    # Content analysis\n",
    "                    'technical_terms_count': result.technical_terms_count,\n",
    "                    'numerical_data_count': result.numerical_data_count,\n",
    "                    'concrete_examples': result.concrete_examples,\n",
    "                    'information_density': result.information_density,\n",
    "                    \n",
    "                    # Quality evaluation flags\n",
    "                    'meets_min_length': quality_eval.get('meets_min_length', False),\n",
    "                    'meets_min_words': quality_eval.get('meets_min_words', False),\n",
    "                    'has_sources': quality_eval.get('has_sources', False),\n",
    "                    'reasonable_response_time': quality_eval.get('reasonable_response_time', False),\n",
    "                    'no_error': quality_eval.get('no_error', False),\n",
    "                    'good_similarity': quality_eval.get('good_similarity', False),\n",
    "                    'technical_content': quality_eval.get('technical_content', False),\n",
    "                    'information_dense': quality_eval.get('information_dense', False),\n",
    "                    'has_examples': quality_eval.get('has_examples', False),\n",
    "                    'has_numbers': quality_eval.get('has_numbers', False),\n",
    "                    \n",
    "                    # Composite quality scores\n",
    "                    'basic_quality_score': quality_eval.get('basic_quality_score', 0.0),\n",
    "                    'advanced_quality_score': quality_eval.get('advanced_quality_score', 0.0),\n",
    "                    'overall_quality_score': quality_eval.get('overall_quality_score', 0.0),\n",
    "                    \n",
    "                    # Raw data (truncated for CSV)\n",
    "                    'answer_preview': result.answer[:200] + ('...' if len(result.answer) > 200 else '') if result.answer else '',\n",
    "                    'similarity_scores_list': str(result.similarity_scores),\n",
    "                    'quality_scores_list': str(result.quality_scores),\n",
    "                    'cross_encoder_scores_list': str(result.cross_encoder_scores)\n",
    "                }\n",
    "                \n",
    "                csv_data.append(row)\n",
    "            \n",
    "            # Create DataFrame and save\n",
    "            df = pd.DataFrame(csv_data)\n",
    "            \n",
    "            # Reorder columns for better readability\n",
    "            column_order = [\n",
    "                'config_name', 'config_id', 'query', 'query_type',\n",
    "                'overall_quality_score', 'basic_quality_score', 'advanced_quality_score',\n",
    "                'response_time_sec', 'answer_length_chars', 'word_count',\n",
    "                'sources_count', 'chunks_used', 'avg_similarity', 'max_similarity',\n",
    "                'technical_terms_count', 'numerical_data_count', 'information_density',\n",
    "                'no_error', 'meets_min_length', 'has_sources', 'good_similarity',\n",
    "                'technical_content', 'has_examples', 'has_numbers',\n",
    "                'cached', 'error', 'answer_preview'\n",
    "            ]\n",
    "            \n",
    "            # Keep only columns that exist\n",
    "            available_columns = [col for col in column_order if col in df.columns]\n",
    "            remaining_columns = [col for col in df.columns if col not in available_columns]\n",
    "            final_column_order = available_columns + remaining_columns\n",
    "            \n",
    "            df = df[final_column_order]\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "            \n",
    "            # Create summary CSV\n",
    "            summary_filename = f'rag_config_summary_{timestamp}.csv'\n",
    "            self.save_config_summary_csv(summary_filename)\n",
    "            \n",
    "            print(f\"‚úÖ CSV results saved to {csv_filename}\")\n",
    "            print(f\"‚úÖ Config summary saved to {summary_filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to save CSV results: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def save_config_summary_csv(self, filename):\n",
    "        \"\"\"Save configuration performance summary to CSV.\"\"\"\n",
    "        try:\n",
    "            summary_data = []\n",
    "            \n",
    "            for config_id, results in self.config_performance.items():\n",
    "                successful = [r for r in results if not r.error]\n",
    "                config_name = results[0].config_name if results else config_id\n",
    "                \n",
    "                if successful:\n",
    "                    # Calculate metrics with safe operations\n",
    "                    response_times = [r.response_time for r in successful]\n",
    "                    quality_scores = [\n",
    "                        self.evaluate_result_quality(r)['overall_quality_score'] \n",
    "                        for r in successful\n",
    "                    ]\n",
    "                    answer_lengths = [r.answer_length for r in successful]\n",
    "                    word_counts = [r.word_count for r in successful]\n",
    "                    sources_counts = [r.sources_count for r in successful]\n",
    "                    similarity_scores = [r.avg_similarity for r in successful if r.avg_similarity > 0]\n",
    "                    technical_terms = [r.technical_terms_count for r in successful]\n",
    "                    numerical_data = [r.numerical_data_count for r in successful]\n",
    "                    info_densities = [r.information_density for r in successful]\n",
    "                    \n",
    "                    avg_time = safe_mean(response_times)\n",
    "                    avg_quality = safe_mean(quality_scores)\n",
    "                    avg_length = safe_mean(answer_lengths)\n",
    "                    avg_word_count = safe_mean(word_counts)\n",
    "                    avg_sources = safe_mean(sources_counts)\n",
    "                    avg_similarity = safe_mean(similarity_scores)\n",
    "                    avg_technical_terms = safe_mean(technical_terms)\n",
    "                    avg_numerical_data = safe_mean(numerical_data)\n",
    "                    avg_info_density = safe_mean(info_densities)\n",
    "                    \n",
    "                    error_rate = (len(results) - len(successful)) / len(results) if len(results) > 0 else 1.0\n",
    "                    \n",
    "                    # Composite score calculation\n",
    "                    speed_bonus = max(0, (10 - avg_time) / 10) if avg_time > 0 else 0\n",
    "                    reliability_bonus = 1 - error_rate\n",
    "                    composite_score = (avg_quality * 0.6 + speed_bonus * 0.2 + reliability_bonus * 0.2)\n",
    "                    \n",
    "                    summary_data.append({\n",
    "                        'config_name': config_name,\n",
    "                        'config_id': config_id,\n",
    "                        'composite_score': composite_score,\n",
    "                        'overall_quality_score': avg_quality,\n",
    "                        'avg_response_time_sec': avg_time,\n",
    "                        'error_rate_percent': error_rate * 100,\n",
    "                        'avg_answer_length': avg_length,\n",
    "                        'avg_word_count': avg_word_count,\n",
    "                        'avg_sources_used': avg_sources,\n",
    "                        'avg_similarity_score': avg_similarity,\n",
    "                        'avg_technical_terms': avg_technical_terms,\n",
    "                        'avg_numerical_data': avg_numerical_data,\n",
    "                        'avg_information_density': avg_info_density,\n",
    "                        'successful_queries': len(successful),\n",
    "                        'total_queries': len(results)\n",
    "                    })\n",
    "                else:\n",
    "                    # All failed\n",
    "                    summary_data.append({\n",
    "                        'config_name': config_name,\n",
    "                        'config_id': config_id,\n",
    "                        'composite_score': 0.0,\n",
    "                        'overall_quality_score': 0.0,\n",
    "                        'avg_response_time_sec': 0.0,\n",
    "                        'error_rate_percent': 100.0,\n",
    "                        'avg_answer_length': 0,\n",
    "                        'avg_word_count': 0,\n",
    "                        'avg_sources_used': 0,\n",
    "                        'avg_similarity_score': 0,\n",
    "                        'avg_technical_terms': 0,\n",
    "                        'avg_numerical_data': 0,\n",
    "                        'avg_information_density': 0,\n",
    "                        'successful_queries': 0,\n",
    "                        'total_queries': len(results)\n",
    "                    })\n",
    "            \n",
    "            # Sort by composite score\n",
    "            summary_data.sort(key=lambda x: x['composite_score'], reverse=True)\n",
    "            \n",
    "            # Add ranking\n",
    "            for i, config in enumerate(summary_data):\n",
    "                config['rank'] = i + 1\n",
    "            \n",
    "            # Create DataFrame and save\n",
    "            df_summary = pd.DataFrame(summary_data)\n",
    "            \n",
    "            # Reorder columns\n",
    "            column_order = [\n",
    "                'rank', 'config_name', 'composite_score', 'overall_quality_score',\n",
    "                'avg_response_time_sec', 'error_rate_percent', 'avg_word_count',\n",
    "                'avg_sources_used', 'avg_similarity_score', 'avg_technical_terms',\n",
    "                'avg_numerical_data', 'avg_information_density', 'successful_queries', 'total_queries'\n",
    "            ]\n",
    "            \n",
    "            df_summary = df_summary[column_order]\n",
    "            df_summary.to_csv(filename, index=False, encoding='utf-8')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to save config summary CSV: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the grid test automatically.\"\"\"\n",
    "    print(\"üöÄ RAG Grid Test - Enhanced Stability Version\")\n",
    "    print(\"üîß This will test 12 LLM configurations with 5 queries each (60 total tests)\")\n",
    "    print(\"‚è±Ô∏è  Estimated time: 15-20 minutes\")\n",
    "    print(\"üõ°Ô∏è  Enhanced error handling for broken pipe and connection issues\")\n",
    "    print(\"‚ö†Ô∏è  Press Ctrl+C to interrupt gracefully and save partial results\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        tester = RAGGridTester()\n",
    "        tester.run_full_test_suite()\n",
    "        \n",
    "        print(\"\\nüéâ Grid test completed successfully!\")\n",
    "        print(\"üìä Check the generated JSON and CSV files for detailed results\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è  Test interrupted by user\")\n",
    "        print(\"üìä Partial results have been saved if any tests completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Test failed with error: {e}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # Ensure cleanup happens\n",
    "        print(\"üßπ Final cleanup...\")\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
